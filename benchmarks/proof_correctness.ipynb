{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2589b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed ms: 8.304415702819824\n"
     ]
    }
   ],
   "source": [
    "import ctypes as ct\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "lib_path = os.path.join(os.getcwd(), \"libflash_attention.so\")\n",
    "lib = ct.CDLL(lib_path)\n",
    "\n",
    "HalfPtr = ct.POINTER(ct.c_uint16)\n",
    "FloatPtr = ct.POINTER(ct.c_float)\n",
    "\n",
    "lib.run_tensor_flash_attention_host_half.argtypes = [\n",
    "    HalfPtr, HalfPtr, HalfPtr, HalfPtr,\n",
    "    ct.c_int, ct.c_int, ct.c_int, ct.c_int, ct.c_int,\n",
    "    ct.c_void_p,\n",
    "    ct.POINTER(ct.c_float)\n",
    "]\n",
    "lib.run_tensor_flash_attention_host_half.restype = None\n",
    "\n",
    "B, H, L, D, tile = 32, 16, 512, 128, 64\n",
    "size = B * H * L * D\n",
    "\n",
    "Q = (np.random.randn(size).astype(np.float16))\n",
    "Q = Q + 0.01 * (np.random.randn(size).astype(np.float16))\n",
    "K = (np.random.randn(size).astype(np.float16))\n",
    "K = K + 0.01 * (np.random.randn(size).astype(np.float16))\n",
    "V = (np.random.randn(size).astype(np.float16))\n",
    "V = V + 0.01 * (np.random.randn(size).astype(np.float16))\n",
    "O = np.zeros(size, dtype=np.float16)\n",
    "\n",
    "Q_p = Q.ctypes.data_as(HalfPtr)\n",
    "K_p = K.ctypes.data_as(HalfPtr)\n",
    "V_p = V.ctypes.data_as(HalfPtr)\n",
    "O_p = O.ctypes.data_as(HalfPtr)\n",
    "\n",
    "elapsed = ct.c_float(0.0)\n",
    "elapsed_p = ct.pointer(elapsed)\n",
    "\n",
    "lib.run_tensor_flash_attention_host_half(\n",
    "    Q_p, K_p, V_p, O_p,\n",
    "    B, H, L, D, tile,\n",
    "    None,\n",
    "    elapsed_p\n",
    ")\n",
    "\n",
    "print(\"Elapsed ms:\", elapsed.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff62864d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "Q_t = torch.from_numpy(Q.reshape(B, H, L, D).astype(np.float16)).to(device)\n",
    "K_t = torch.from_numpy(K.reshape(B, H, L, D).astype(np.float16)).to(device)\n",
    "V_t = torch.from_numpy(V.reshape(B, H, L, D).astype(np.float16)).to(device)\n",
    "\n",
    "try:\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cuda.enable_flash_sdp(True)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "O_ref = torch.nn.functional.scaled_dot_product_attention(\n",
    "    Q_t, K_t, V_t, attn_mask=None, dropout_p=0.0, is_causal=False\n",
    ")\n",
    "\n",
    "O_ref_np = O_ref.detach().cpu().numpy().reshape(-1)\n",
    "O_np = O\n",
    "\n",
    "mae = np.mean(np.abs(O_ref_np.astype(np.float32) - O_np.astype(np.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4bb0b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "assert 'O_ref_np' in globals() and 'O' in globals(), \"Reference or output not found\"\n",
    "O_kernel = O.astype(np.float32)\n",
    "O_ref32 = O_ref_np.astype(np.float32)\n",
    "\n",
    "diff = O_ref32 - O_kernel\n",
    "abs_diff = np.abs(diff)\n",
    "\n",
    "mae = float(np.mean(abs_diff))\n",
    "nonzero_mask = np.abs(O_ref32) > 0\n",
    "if np.any(nonzero_mask):\n",
    "    mre = float(np.mean(np.abs(diff[nonzero_mask]) / np.abs(O_ref32[nonzero_mask])))\n",
    "else:\n",
    "    mre = float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14b354f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "assert 'Q_t' in globals() and 'K_t' in globals() and 'V_t' in globals(), \"Run the PyTorch prep cell first\"\n",
    "\n",
    "try:\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cuda.enable_flash_sdp(True)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "Q16 = Q_t.to(torch.float16)\n",
    "K16 = K_t.to(torch.float16)\n",
    "V16 = V_t.to(torch.float16)\n",
    "\n",
    "O_flash16 = torch.nn.functional.scaled_dot_product_attention(\n",
    "    Q16, K16, V16, attn_mask=None, dropout_p=0.0, is_causal=False\n",
    ")\n",
    "\n",
    "O_flash16_np = O_flash16.detach().cpu().numpy().reshape(-1).astype(np.float16)\n",
    "\n",
    "O_kernel16 = O.astype(np.float16)\n",
    "diff16 = O_flash16_np.astype(np.float16).astype(np.float32) - O_kernel16.astype(np.float16).astype(np.float32)\n",
    "abs_diff16 = np.abs(diff16)\n",
    "\n",
    "mae16 = float(np.mean(abs_diff16))\n",
    "ref32 = O_flash16_np.astype(np.float32)\n",
    "nonzero_mask16 = np.abs(ref32) > 0\n",
    "mre16 = float(np.mean(np.abs(diff16[nonzero_mask16]) / np.abs(ref32[nonzero_mask16]))) if np.any(nonzero_mask16) else float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2100755c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy vs Kernel:\n",
      "  MAE:   5.7072058552876115e-05\n",
      "  MRE:   0.006194089539349079\n",
      "NumPy vs PyTorch Flash SDP:\n",
      "  MAE:   1.0230122825305443e-05\n",
      "  MRE:   0.0016731568612158298\n",
      "NumPy vs PyTorch Flash SDP:\n",
      "  MAE:   1.0230122825305443e-05\n",
      "  MRE:   0.0016731568612158298\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def flash_attention_numpy(Q_bhl_d, K_bhl_d, V_bhl_d, tile: int, return_fp16: bool = True):\n",
    "    assert Q_bhl_d.ndim == 4 and K_bhl_d.ndim == 4 and V_bhl_d.ndim == 4\n",
    "    B, H, L, D = Q_bhl_d.shape\n",
    "    assert K_bhl_d.shape == (B, H, L, D)\n",
    "    assert V_bhl_d.shape == (B, H, L, D)\n",
    "    assert tile > 0 and tile <= L\n",
    "\n",
    "    Q = Q_bhl_d.astype(np.float32, copy=False)\n",
    "    K = K_bhl_d.astype(np.float32, copy=False)\n",
    "    V = V_bhl_d.astype(np.float32, copy=False)\n",
    "\n",
    "    scale = 1.0 / np.sqrt(float(D))\n",
    "\n",
    "    O = np.zeros((B, H, L, D), dtype=np.float32)\n",
    "\n",
    "    m_i = np.full((B, H, L), -np.inf, dtype=np.float32)\n",
    "    l_i = np.zeros((B, H, L), dtype=np.float32)\n",
    "    o_i = np.zeros((B, H, L, D), dtype=np.float32)\n",
    "\n",
    "    for start in range(0, L, tile):\n",
    "        end = min(start + tile, L)\n",
    "        K_tile = K[:, :, start:end, :]\n",
    "        V_tile = V[:, :, start:end, :]\n",
    "\n",
    "        S = np.einsum('bhld,bhTd->bh lT', Q, K_tile, optimize=True) * scale\n",
    "        m_ij = np.max(S, axis=-1)\n",
    "        m_new = np.maximum(m_i, m_ij)\n",
    "        S_shift = S - m_new[..., None]\n",
    "        P = np.exp(S_shift)\n",
    "        alpha = np.exp(m_i - m_new)\n",
    "        l_new = alpha * l_i + np.sum(P, axis=-1)\n",
    "        PV = np.einsum('bh lT,bhTd->bh ld', P, V_tile, optimize=True)\n",
    "        o_new = alpha[..., None] * o_i + PV\n",
    "        m_i = m_new\n",
    "        l_i = l_new\n",
    "        o_i = o_new\n",
    "\n",
    "    O = o_i / l_i[..., None]\n",
    "\n",
    "    if return_fp16:\n",
    "        return O.astype(np.float16)\n",
    "    return O\n",
    "\n",
    "try:\n",
    "    assert 'Q' in globals() and 'K' in globals() and 'V' in globals()\n",
    "    B_, H_, L_, D_ = B, H, L, D\n",
    "    Q4 = Q.reshape(B_, H_, L_, D_)\n",
    "    K4 = K.reshape(B_, H_, L_, D_)\n",
    "    V4 = V.reshape(B_, H_, L_, D_)\n",
    "\n",
    "    tile_size = 64\n",
    "    O_np_flash16 = flash_attention_numpy(Q4, K4, V4, tile=tile_size, return_fp16=True)\n",
    "    O_np_flash32 = O_np_flash16.astype(np.float32)\n",
    "\n",
    "    O_kernel16 = O.astype(np.float16)\n",
    "    O_kernel32 = O_kernel16.astype(np.float32)\n",
    "\n",
    "    diff_k = O_np_flash32.reshape(-1) - O_kernel32.reshape(-1)\n",
    "    abs_diff_k = np.abs(diff_k)\n",
    "    mae_k = float(np.mean(abs_diff_k))\n",
    "    ref32_k = O_kernel32.reshape(-1)\n",
    "    nz_k = np.abs(ref32_k) > 0\n",
    "    mre_k = float(np.mean(np.abs(diff_k[nz_k]) / np.abs(ref32_k[nz_k]))) if np.any(nz_k) else float('nan')\n",
    "\n",
    "    print('NumPy vs Kernel:')\n",
    "    print(f'  MAE:   {mae_k}')\n",
    "    print(f'  MRE:   {mre_k}')\n",
    "\n",
    "    if 'O_flash16_np' in globals():\n",
    "        O_torch32 = O_flash16_np.astype(np.float32)\n",
    "        diff_t = O_np_flash32.reshape(-1) - O_torch32.reshape(-1)\n",
    "        abs_diff_t = np.abs(diff_t)\n",
    "        mae_t = float(np.mean(abs_diff_t))\n",
    "        ref32_t = O_torch32.reshape(-1)\n",
    "        nz_t = np.abs(ref32_t) > 0\n",
    "        mre_t = float(np.mean(np.abs(diff_t[nz_t]) / np.abs(ref32_t[nz_t]))) if np.any(nz_t) else float('nan')\n",
    "\n",
    "        print('NumPy vs PyTorch Flash SDP:')\n",
    "        print(f'  MAE:   {mae_t}')\n",
    "        print(f'  MRE:   {mre_t}')\n",
    "    else:\n",
    "        print('PyTorch Flash SDP output not found; run the PyTorch Flash cell first to compare.')\n",
    "except Exception as e:\n",
    "    print('Skip comparisons until inputs are prepared:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97a0c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel_vs_numpy\n",
      "  MAE: 5.7072058552876115e-05\n",
      "  MRE: 0.006194089539349079\n",
      "kernel_vs_torch\n",
      "  MAE: 6.050314550520852e-05\n",
      "  MRE: 0.007585969753563404\n",
      "numpy_vs_torch\n",
      "  MAE: 1.0230122825305443e-05\n",
      "  MRE: 0.0016731568612158298\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "summary = {}\n",
    "\n",
    "if 'O_np_flash32' in globals():\n",
    "    O_kernel32 = O.astype(np.float32)\n",
    "    diff_kn = O_kernel32.reshape(-1) - O_np_flash32.reshape(-1)\n",
    "    ad_kn = np.abs(diff_kn)\n",
    "    summary['kernel_vs_numpy'] = {\n",
    "        'MAE': float(np.mean(ad_kn)),\n",
    "        'MRE': float(np.mean(np.abs(diff_kn[np.abs(O_kernel32.reshape(-1))>0]) / np.abs(O_kernel32.reshape(-1)[np.abs(O_kernel32.reshape(-1))>0]))) if np.any(np.abs(O_kernel32.reshape(-1))>0) else float('nan'),\n",
    "    }\n",
    "\n",
    "if 'O_flash16_np' in globals():\n",
    "    O_torch32 = O_flash16_np.astype(np.float32)\n",
    "    diff_kt = O_kernel32.reshape(-1) - O_torch32.reshape(-1)\n",
    "    ad_kt = np.abs(diff_kt)\n",
    "    summary['kernel_vs_torch'] = {\n",
    "        'MAE': float(np.mean(ad_kt)),\n",
    "        'MRE': float(np.mean(np.abs(diff_kt[np.abs(O_torch32.reshape(-1))>0]) / np.abs(O_torch32.reshape(-1)[np.abs(O_torch32.reshape(-1))>0]))) if np.any(np.abs(O_torch32.reshape(-1))>0) else float('nan'),\n",
    "    }\n",
    "\n",
    "if 'O_np_flash32' in globals() and 'O_flash16_np' in globals():\n",
    "    O_torch32 = O_flash16_np.astype(np.float32)\n",
    "    diff_nt = O_np_flash32.reshape(-1) - O_torch32.reshape(-1)\n",
    "    ad_nt = np.abs(diff_nt)\n",
    "    summary['numpy_vs_torch'] = {\n",
    "        'MAE': float(np.mean(ad_nt)),\n",
    "        'MRE': float(np.mean(np.abs(diff_nt[np.abs(O_torch32.reshape(-1))>0]) / np.abs(O_torch32.reshape(-1)[np.abs(O_torch32.reshape(-1))>0]))) if np.any(np.abs(O_torch32.reshape(-1))>0) else float('nan'),\n",
    "    }\n",
    "    \n",
    "for k, v in summary.items():\n",
    "    print(k)\n",
    "    for mk, mv in v.items():\n",
    "        print(f\"  {mk}: {mv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
